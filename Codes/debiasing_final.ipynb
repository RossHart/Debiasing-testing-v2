{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from scipy.stats import binned_statistic, scoreatpercentile\n",
    "import pickle\n",
    "from scipy.optimize import minimize\n",
    "import time\n",
    "from voronoi_2d_binning import voronoi_2d_binning\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "import imp # reload modules if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import binning\n",
    "import bin_debiasing\n",
    "import fit_debiasing\n",
    "import make_dictionaries\n",
    "import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('output_files/') if os.path.isdir('output_files/') is False else None\n",
    "\n",
    "source_directory = params.source_directory\n",
    "full_sample = params.full_sample\n",
    "\n",
    "#save_directory = params.numpy_save_directory\n",
    "\n",
    "min_log_fv = -1.5\n",
    "max_log_fv = 0.01 # if >0, there is no upper limit to fitting fv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded galaxy data...\n",
      "Loaded questions...\n",
      "Loaded functions...\n"
     ]
    }
   ],
   "source": [
    "#full_data = Table.read(source_directory + full_sample)\n",
    "full_data = Table.read(source_directory + 'full_sample_debiased_base.fits')\n",
    "print('Loaded galaxy data...')\n",
    "questions = make_dictionaries.questions\n",
    "print('Loaded questions...')\n",
    "function_dictionary = make_dictionaries.function_dictionary\n",
    "print('Loaded functions...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reduce_sample(full_data,questions,question,p_cut=0.5,N_cut=5,normalised_values=True):\n",
    "    \n",
    "    # Get the reference sample from the previous data:\n",
    "    \n",
    "    previous_q = questions[question]['pre_questions']\n",
    "    previous_a = questions[question]['pre_answers']\n",
    "    \n",
    "    if normalised_values == True:\n",
    "        suffix = '_debiased_rh'\n",
    "    else:\n",
    "        suffix = '_debiased_rh_normalised'\n",
    "    \n",
    "    if previous_q != None:\n",
    "        \n",
    "        p_col = np.ones(len(full_data))\n",
    "        \n",
    "        for m in range(len(previous_q)):\n",
    "            p_col = p_col*(full_data[previous_q[m] + '_' + previous_a[m] + suffix])\n",
    "        N_col = (full_data[previous_q[-1] + '_' + previous_a[-1] + '_count'])\n",
    "        \n",
    "        select = (p_col > p_cut) & (N_col >= N_cut)\n",
    "        data_reduced = full_data[select]\n",
    "        print('{}/{} galaxies with p>{} and N>={}.'.format(len(data_reduced),\n",
    "                                                          len(full_data),p_cut,N_cut))\n",
    "    \n",
    "    else:\n",
    "        data_reduced = full_data.copy()\n",
    "        print('Primary question, so all {} galaxies used.'.format(len(data_reduced)))\n",
    "    \n",
    "    return data_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bins(question,answer):\n",
    "    '''Get bins from if they have already been created from a \n",
    "    previous running of the debiasing'''\n",
    "    \n",
    "    bins = Table.read('output_files/'+ question + '/' + answer + '/bins.fits')\n",
    "    all_bins = Table.read('output_files/'+ question + '/' + answer + '/all_bins.fits')\n",
    "    vbins_table = Table.read('output_files/'+ question + '/' + answer + '/vbin_parameters.fits')\n",
    "    \n",
    "    vbins = bins['vbin']\n",
    "    zbins = bins['zbin']\n",
    "    zbins_coarse = bins['coarse_zbin']\n",
    "    vbins_all = all_bins['vbin']\n",
    "    zbins_all = all_bins['zbin']\n",
    "    zbins_coarse_all = all_bins['coarse_zbin']\n",
    "    \n",
    "    return vbins,zbins,zbins_coarse,vbins_all,zbins_all,zbins_coarse_all,vbins_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_01_range(dataset):\n",
    "    '''Returns proportion of 0s and 1s to be 'excluded' from the histograms'''\n",
    "    cf_low = np.sum(dataset == 0)/len(dataset)\n",
    "    N_1 = np.sum(dataset == 1)/len(dataset)\n",
    "    cf_high = 1-N_1\n",
    "    \n",
    "    return cf_low,cf_high\n",
    "\n",
    "\n",
    "def set_01_values(dataset,cf_low,cf_high):\n",
    "    '''Set the top and bottom ends to 0 and 1, to avoid 'false' rms values from 'undebiasable' values'''\n",
    "    \n",
    "    cf = np.linspace(0,1,len(dataset))\n",
    "    d_sorted = np.sort(dataset)\n",
    "    \n",
    "    indices = np.searchsorted(cf,[cf_low,cf_high])\n",
    "    indices = indices.clip(0,len(cf)-1)\n",
    "    \n",
    "    d_sorted[0:indices[0]] = 0\n",
    "    d_sorted[indices[1]:] = 1\n",
    "    \n",
    "    return d_sorted\n",
    "\n",
    "\n",
    "def histogram_fractions(data,hist_bins):\n",
    "    h,bin_edges = np.histogram(data,bins=hist_bins)\n",
    "    f = h/np.sum(h)\n",
    "    return f\n",
    "\n",
    "\n",
    "def get_rms(dataset,z_assignments,reference,hist_bins):\n",
    "    \n",
    "    ref_low,ref_high = get_01_range(reference)\n",
    "    \n",
    "    x = len(hist_bins) - 1\n",
    "    y = len(np.unique(z_assignments))\n",
    "    rms_array = np.zeros((x,y))\n",
    "\n",
    "    for n,z in enumerate(np.unique(z_assignments)):\n",
    "    \n",
    "        ref = reference.copy()\n",
    "        vl_deb = dataset[z_assignments == z]\n",
    "\n",
    "        deb_low,deb_high = get_01_range(vl_deb)\n",
    "        cf_low = np.max([ref_low,deb_low])\n",
    "        cf_high = np.min([ref_high,deb_high])\n",
    "    \n",
    "        vl_deb_01 = set_01_values(vl_deb,cf_low,cf_high)\n",
    "        ref_01 = set_01_values(ref,cf_low,cf_high)\n",
    "    \n",
    "        f_deb = histogram_fractions(vl_deb_01,hist_bins)\n",
    "        f_ref = histogram_fractions(ref_01,hist_bins)\n",
    "        \n",
    "        rms_array[:,n] = np.absolute(f_deb - f_ref)\n",
    "    \n",
    "    rms_value = np.mean(rms_array)  \n",
    "    \n",
    "    return rms_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_best_function(raw_data,debiased,question,answer):\n",
    "    \n",
    "    volume_ok = raw_data['in_volume_limit'] == 1\n",
    "    \n",
    "    vl  = raw_data[volume_ok][question + '_' + answer + '_weighted_fraction']\n",
    "    vl_bin = debiased['bin_method'][volume_ok]\n",
    "    vl_fit = debiased['fit_method'][volume_ok]\n",
    "    \n",
    "    redshifts = full_data['REDSHIFT_1'][volume_ok]\n",
    "    z_range = [np.min(redshifts),np.max(redshifts)]\n",
    "    z_vl_bins = np.linspace(z_range[0],z_range[1],11) # have 11 bins for now\n",
    "    z_vl_bins[0],z_vl_bins[-1] = [0,1] # ensure all data gets binned\n",
    "    z_assignments = np.digitize(redshifts,z_vl_bins)\n",
    "    \n",
    "    hist_bins = np.linspace(0,1,11)\n",
    "    hist_bins[0],hist_bins[-1] = [-1,2] # ensure all data gets binned\n",
    "\n",
    "    reference = vl[z_assignments == 1] # raw low-z for comparison\n",
    "    \n",
    "    rms_bin = get_rms(vl_bin,z_assignments,reference,hist_bins)\n",
    "    rms_fit = get_rms(vl_fit,z_assignments,reference,hist_bins)\n",
    "    \n",
    "    print('rms(bin) = {0:.3f}'.format(rms_bin))\n",
    "    print('rms(fit) = {0:.3f}'.format(rms_fit))\n",
    "    if rms_bin < rms_fit:\n",
    "        print('---> bin method selected')\n",
    "        debiased_values = debiased['bin_method']\n",
    "    else:\n",
    "        print('---> fit method selected')\n",
    "        debiased_values = debiased['fit_method']\n",
    "        \n",
    "    return debiased_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bin_and_debias(full_data,question,questions,answer,bins_exist=False,n_per_bin=100,coarse=False):\n",
    "    '''Set to 'coarse' to make the fitting only apply to the 'coarse binning'of 4 redshift bins per \n",
    "    voronoi bin rather than the fully binned data'''\n",
    "    \n",
    "    (os.mkdir('output_files/'+ question) if\n",
    "     os.path.isdir('output_files/'+ question) is False else None)\n",
    "    (os.mkdir('output_files/'+ question + '/' + answer) if\n",
    "     os.path.isdir('output_files/'+ question + '/' + answer) is False else None)\n",
    "    \n",
    "    data = reduce_sample(full_data,questions,question)\n",
    "    \n",
    "    if bins_exist == True:\n",
    "        vbins,zbins,zbins_coarse,vbins_all,zbins_all,zbins_coarse_all,vbins_table = get_bins(question,answer)\n",
    "        print('Bins obtained from previous iteration...')\n",
    "        \n",
    "    else:\n",
    "        vbins,zbins,zbins_coarse,vbins_all,zbins_all,zbins_coarse_all,vbins_table = binning.bin_data(data,\n",
    "                                                                                                     full_data,\n",
    "                                                                                                     question,\n",
    "                                                                                                     answer,\n",
    "                                                                                                     plot=False,\n",
    "                                                                                                     signal=n_per_bin)\n",
    "        \n",
    "    # Save the binning data  \n",
    "    bin_table = Table([vbins,zbins,zbins_coarse],names=('vbin','zbin','coarse_zbin'))\n",
    "    all_bin_table = Table([vbins_all,zbins_all,zbins_coarse_all],names=('vbin','zbin','coarse_zbin'))\n",
    "    bin_table.write('output_files/'+ question + '/' + answer + '/bins.fits',overwrite=True)\n",
    "    all_bin_table.write('output_files/'+ question + '/' + answer + '/all_bins.fits',overwrite=True)\n",
    "    vbins_table.write('output_files/'+ question + '/' + answer + '/vbin_parameters.fits',overwrite=True)\n",
    "\n",
    "    \n",
    "    debiased_bin = bin_debiasing.debias(data,full_data,vbins,zbins,vbins_all,zbins_all,question,answer)\n",
    "    debiased_fit,dout,fit_setup,zbins,fit_vbin_results = fit_debiasing.debias_by_fit(data,full_data,vbins,zbins,\n",
    "                                                                                     zbins_coarse,question,answer,\n",
    "                                                                                     function_dictionary,min_log_fv,\n",
    "                                                                                     coarse=coarse)\n",
    "    \n",
    "    volume_ok = data['in_volume_limit'] == 1    \n",
    "    vl_data = full_data[volume_ok]\n",
    "    vl_fit = debiased_fit[volume_ok]\n",
    "    vl_bin = debiased_bin[volume_ok]\n",
    "\n",
    "    debiased_table = Table([debiased_bin,debiased_fit],names=('bin_method','fit_method'))\n",
    "    debiased_table.write('output_files/'+ question + '/' + answer + '/debiased.fits',overwrite=True)\n",
    "    dout.write('output_files/'+ question + '/' + answer + '/fit_results.fits',overwrite=True)\n",
    "    pickle.dump(fit_setup,open('output_files/'+ question + '/' + answer + '/fit_setup.p', \"wb\" ))\n",
    "    \n",
    "    return debiased_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Question to be debiased: t04_spiral\n",
      "Answer to be debiased: a08_spiral\n",
      "95560/219212 galaxies with p>0.5 and N>=5.\n",
      "Bin-accretion...\n",
      "655  initial bins.\n",
      "Reassign bad bins...\n",
      "20  good bins.\n",
      "Modified Lloyd algorithm...\n",
      "18  iterations.\n",
      "Unbinned pixels:  0  /  13115\n",
      "Fractional S/N scatter (%): 10.7703134276\n",
      "20 voronoi bins\n",
      "42.2 redshift bins per voronoi bin\n",
      "All bins fitted! 26.098473072052002s in total\n",
      "chisq(logistic) = 0.00043103927162539744\n",
      "All bins fitted! 19.00503897666931s in total\n",
      "chisq(exp. power) = 4.8797415615015555e-05\n",
      "All bins fitted! 18.308588981628418s in total"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosshart/Documents/Github_repos/Debiasing-testing-v2/Codes/fit_debiasing.py:256: RuntimeWarning: invalid value encountered in log10\n",
      "  term = constant*np.log10(var)\n",
      "/Users/rosshart/anaconda/lib/python3.4/site-packages/scipy/optimize/minpack.py:604: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/Users/rosshart/anaconda/lib/python3.4/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/Users/rosshart/anaconda/lib/python3.4/site-packages/numpy/core/_methods.py:71: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rosshart/Documents/Github_repos/Debiasing-testing-v2/Codes/fit_debiasing.py:371: RuntimeWarning: invalid value encountered in less\n",
      "  k[k < kmin] = kmin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rms(bin) = 0.025\n",
      "rms(fit) = 0.025\n",
      "---> fit method selected\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Question to be debiased: t04_spiral\n",
      "Answer to be debiased: a09_no_spiral\n",
      "95560/219212 galaxies with p>0.5 and N>=5.\n",
      "Bin-accretion...\n",
      "565  initial bins.\n",
      "Reassign bad bins...\n",
      "21  good bins.\n",
      "Modified Lloyd algorithm...\n",
      "19  iterations.\n",
      "Unbinned pixels:  0  /  12079\n",
      "Fractional S/N scatter (%): 13.1365413299\n",
      "21 voronoi bins\n",
      "40.476190476190474 redshift bins per voronoi bin\n",
      "All bins fitted! 22.333016872406006s in total\n",
      "chisq(logistic) = 0.0003983463188977766\n",
      "All bins fitted! 22.603487014770508s in total\n",
      "chisq(exp. power) = 0.0001328481800800105\n",
      "All bins fitted! 23.823745012283325s in total"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosshart/Documents/Github_repos/Debiasing-testing-v2/Codes/fit_debiasing.py:372: RuntimeWarning: invalid value encountered in greater\n",
      "  k[k > kmax] = kmax\n",
      "/Users/rosshart/Documents/Github_repos/Debiasing-testing-v2/Codes/fit_debiasing.py:380: RuntimeWarning: invalid value encountered in less\n",
      "  kb[kb < kmin] = kmin\n",
      "/Users/rosshart/Documents/Github_repos/Debiasing-testing-v2/Codes/fit_debiasing.py:381: RuntimeWarning: invalid value encountered in greater\n",
      "  kb[kb > kmax] = kmax\n",
      "/Users/rosshart/Documents/Github_repos/Debiasing-testing-v2/Codes/make_dictionaries.py:28: RuntimeWarning: invalid value encountered in greater\n",
      "  ok = k > 0\n",
      "/Users/rosshart/Documents/Github_repos/Debiasing-testing-v2/Codes/fit_debiasing.py:373: RuntimeWarning: invalid value encountered in less\n",
      "  c[c < cmin] = cmin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rms(bin) = 0.023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rosshart/Documents/Github_repos/Debiasing-testing-v2/Codes/fit_debiasing.py:374: RuntimeWarning: invalid value encountered in greater\n",
      "  c[c > cmax] = cmax\n",
      "/Users/rosshart/Documents/Github_repos/Debiasing-testing-v2/Codes/fit_debiasing.py:382: RuntimeWarning: invalid value encountered in less\n",
      "  cb[cb < cmin] = cmin\n",
      "/Users/rosshart/Documents/Github_repos/Debiasing-testing-v2/Codes/fit_debiasing.py:383: RuntimeWarning: invalid value encountered in greater\n",
      "  cb[cb > cmax] = cmax\n",
      "/Users/rosshart/anaconda/lib/python3.4/site-packages/IPython/kernel/__main__.py:33: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rms(fit) = 0.027\n",
      "---> bin method selected\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "imp.reload(fit_debiasing)\n",
    "'''\n",
    "question_order = ['t01_smooth_or_features',\n",
    "                  't02_edgeon',\n",
    "                  't04_spiral',\n",
    "                  't11_arms_number']\n",
    "'''\n",
    "\n",
    "\n",
    "question_order = ['t04_spiral']\n",
    "\n",
    "for question in question_order:\n",
    "    answers = questions[question]['answers']\n",
    "    #answers = ['a36_more_than_4']\n",
    "    for answer in answers:\n",
    "        \n",
    "        #bins_exist = os.path.isfile('output_files/'+ question + '/' + answer + '/bins.fits')\n",
    "        bins_exist = False\n",
    "        \n",
    "        print('----------------------------------')\n",
    "        print('Question to be debiased:',question)\n",
    "        print('Answer to be debiased:',answer)\n",
    "        \n",
    "        debiased = bin_and_debias(full_data,question,questions,answer,\n",
    "                                  bins_exist=bins_exist,n_per_bin=100,coarse=True) # set to coarse to test method.\n",
    "        \n",
    "        deb_vals = choose_best_function(full_data,debiased,question,answer)\n",
    "        full_data[question + '_' + answer + '_debiased_rh'] = deb_vals\n",
    "        \n",
    "        print('----------------------------------')\n",
    "\n",
    "    debiased_values = np.array([full_data[question + '_' + a + '_debiased_rh'] for a in answers])\n",
    "    debiased_norm = debiased_values/np.sum(debiased_values,axis=0)\n",
    "    debiased_norm[np.isnan(debiased_norm)] = 0\n",
    "    for m in range(len(debiased_norm)):\n",
    "        full_data[question + '_' + answers[m] + '_debiased_rh_normalised'] = debiased_norm[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "debiased_columns = []\n",
    "\n",
    "for m in range(len(full_data.colnames)):\n",
    "    c = full_data.colnames[m]\n",
    "    if 'debiased_rh' in c:\n",
    "        debiased_columns.append(c)\n",
    "        \n",
    "debiased_values = full_data[debiased_columns]\n",
    "debiased_values.write(source_directory + 'debiased_values.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data.write(source_directory + 'full_sample_debiased.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
