{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import make_dictionaries\n",
    "import os\n",
    "import math\n",
    "import params\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from scipy.stats import binned_statistic, scoreatpercentile\n",
    "import pickle\n",
    "from scipy.optimize import minimize\n",
    "import time\n",
    "from voronoi_2d_binning import voronoi_2d_binning\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import binning\n",
    "import bin_debiasing\n",
    "import fit_debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "# better-looking plots\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8)\n",
    "plt.rcParams['font.size'] = 18\n",
    "mpl.ticker.AutoLocator.default_params['nbins'] = 5\n",
    "mpl.ticker.AutoLocator.default_params['prune'] = 'both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('output_files/') if os.path.isdir('output_files/') is False else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_directory = params.source_directory\n",
    "save_directory = params.numpy_save_directory\n",
    "full_sample = params.full_sample\n",
    "volume_limited_sample = params.volume_limited_sample\n",
    "question = params.question\n",
    "bins_to_plot = params.bins_to_plot\n",
    "#print('Question to be debiased: {}'.format(question))\n",
    "\n",
    "min_log_fv = -1.5\n",
    "max_log_fv = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded galaxy data...\n",
      "Loaded questions...\n",
      "Loaded functions...\n"
     ]
    }
   ],
   "source": [
    "full_data = Table.read(source_directory + full_sample)\n",
    "print('Loaded galaxy data...')\n",
    "questions = make_dictionaries.questions\n",
    "print('Loaded questions...')\n",
    "function_dictionary = make_dictionaries.function_dictionary\n",
    "print('Loaded functions...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debias_by_fit(data,full_data,vbins,zbins,zbins_coarse,function_dictionary,min_log_fv):\n",
    "    \n",
    "    fit_setup = fit_debiasing.get_best_function(data,vbins,zbins_coarse,function_dictionary,\n",
    "                                            question,answer,min_log_fv)\n",
    "    \n",
    "    #fit_vbin_results = fit_debiasing.fit_vbin_function(data, vbins, zbins_coarse, fit_setup,\n",
    "                                                   #question,answer,min_log_fv)\n",
    "    \n",
    "    fit_vbin_results = fit_debiasing.fit_vbin_function(data, vbins, zbins, fit_setup,\n",
    "                                                   question,answer,min_log_fv)\n",
    "    \n",
    "    k_func,c_func = fit_debiasing.get_kc_functions(fit_vbin_results)\n",
    "    \n",
    "    kparams, cparams,dout, kmin, kmax, cmin, cmax = fit_debiasing.fit_mrz(fit_vbin_results, k_func,\n",
    "                                                                      c_func,clip=2,plot=False)\n",
    "    \n",
    "    debiased_fit = fit_debiasing.debias(full_data,0.03, k_func,c_func, kparams, cparams,\n",
    "                                    question,answer,kmin,kmax,cmin,cmax,fit_setup)\n",
    "\n",
    "    # Debias ALL of the data \n",
    "    \n",
    "    return debiased_fit,dout,fit_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-050aad778514>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-050aad778514>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    h0 =\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMS of the volume limited sample: -----\n",
    "\n",
    "def histogram_fractions(data,hist_bins):\n",
    "    h,bin_edges = np.histogram(data,bins=hist_bins)\n",
    "    f = h/np.sum(h)\n",
    "    \n",
    "    # Remove proportion of 0s and proportion of 1s:\n",
    "    \n",
    "    cf = np.linspace(0,1,len(data))\n",
    "    plt.plot(np.sort(data),cf)\n",
    "    indices = np.searchsorted(data,[10**(-5),1-(10)**(-5)])\n",
    "    cf_range = cf[indices.clip(0, len(cf)-1)]\n",
    "    \n",
    "    return f,cf_range\n",
    "\n",
    "\n",
    "def choose_best_function(vl_data,vl_fit,vl_bin,debiased_fit,debiased_bin):\n",
    "\n",
    "    hist_bins = np.linspace(0,1,11)\n",
    "    hist_bins[-1] = 2\n",
    "    hist_bins[0] = -1\n",
    "\n",
    "    # First divide the data into 10 redshift bins:\n",
    "    z_range = [np.min(vl_data['REDSHIFT_1']),np.max(vl_data['REDSHIFT_1'])]\n",
    "    z_bin_edges = np.linspace(z_range[0],z_range[1],11)\n",
    "    z_bin_edges[0] = 0 # Ensure all data is binned\n",
    "    z_bin_edges[-1] = 1 # Ensure all data is binned\n",
    "    z_bin_assign = np.digitize(vl_data['REDSHIFT_1'],bins=z_bin_edges) # 10 bins\n",
    "\n",
    "    low_z_reference = vl_data[z_bin_assign == 1][question + '_' + answer + '_weighted_fraction']\n",
    "\n",
    "    rms_bin_array = np.zeros((10,10))\n",
    "    rms_fit_array = np.zeros((10,10))\n",
    "\n",
    "    f_reference = histogram_fractions(low_z_reference,hist_bins)\n",
    "\n",
    "    for i,z_i in enumerate(np.unique(z_bin_assign)):\n",
    "    \n",
    "        high_z_select = z_bin_assign == z_i\n",
    "        vl_fit_h = vl_fit[high_z_select]\n",
    "        vl_bin_h = vl_bin[high_z_select]\n",
    "    \n",
    "        f_fit = histogram_fractions(vl_fit_h,hist_bins)\n",
    "        f_bin = histogram_fractions(vl_bin_h,hist_bins)\n",
    "    \n",
    "        rms_fit_array[i] = np.absolute(f_fit - f_reference)\n",
    "        rms_bin_array[i] = np.absolute(f_bin - f_reference)\n",
    "        \n",
    "    rms_bin_array[:,0] = 0 # ignore the lowest bin?\n",
    "    rms_fit_array[:,0] = 0 # ignore the lowest bin?\n",
    "    \n",
    "    bin_residual = np.sum(rms_bin_array)/10\n",
    "    fit_residual = np.sum(rms_fit_array)/10\n",
    "\n",
    "    print('RMS residual from fitting method = {0:.3f}'.format(fit_residual))\n",
    "    print('RMS residual from binning method = {0:.3f}'.format(bin_residual))\n",
    "\n",
    "    if fit_residual > bin_residual:\n",
    "        print('---> Binning method selected')\n",
    "        debiased = debiased_bin.copy()\n",
    "    else:\n",
    "        print('---> Fitting method selected')\n",
    "        debiased = debiased_fit.copy()\n",
    "        \n",
    "    return debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reduce_sample(full_data,questions,question,p_cut=0.5,N_cut=5):\n",
    "    \n",
    "    # Get the reference sample from the previous data:\n",
    "    \n",
    "    previous_q = questions[question]['pre_questions']\n",
    "    previous_a = questions[question]['pre_answers']\n",
    "    \n",
    "    if previous_q != None:\n",
    "        \n",
    "        p_col = np.ones(len(full_data))\n",
    "        \n",
    "        for m in range(len(previous_q)):\n",
    "            p_col = p_col*(full_data[previous_q[m] + '_' + previous_a[m] + '_debiased_rh'])\n",
    "        N_col = (full_data[previous_q[-1] + '_' + previous_a[-1] + '_count'])\n",
    "        \n",
    "        select = (p_col > p_cut) & (N_col >= N_cut)\n",
    "        data_reduced = full_data[select]\n",
    "        print('{}/{} galaxies with p>{} and N>={}.'.format(len(data_reduced),\n",
    "                                                          len(full_data),p_cut,N_cut))\n",
    "    \n",
    "    else:\n",
    "        data_reduced = full_data.copy()\n",
    "        print('Primary question, so all {} galaxies used.'.format(len(data_reduced)))\n",
    "    \n",
    "    return data_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bins(question,answer):\n",
    "    \n",
    "    bins = Table.read('output_files/'+ question + '/' + answer + '/bins.fits')\n",
    "    all_bins = Table.read('output_files/'+ question + '/' + answer + '/all_bins.fits')\n",
    "    vbins_table = Table.read('output_files/'+ question + '/' + answer + '/vbin_parameters.fits')\n",
    "    \n",
    "    vbins = bins['vbin']\n",
    "    zbins = bins['zbin']\n",
    "    zbins_coarse = bins['coarse_zbin']\n",
    "    vbins_all = all_bins['vbin']\n",
    "    zbins_all = all_bins['zbin']\n",
    "    zbins_coarse_all = all_bins['coarse_zbin']\n",
    "    \n",
    "    return vbins,zbins,zbins_coarse,vbins_all,zbins_all,zbins_coarse_all,vbins_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bin_and_debias(full_data,question,questions,answer,bins_exist=False,n_per_bin=100):\n",
    "    \n",
    "    data = reduce_sample(full_data,questions,question)\n",
    "    \n",
    "    if bins_exist == True:\n",
    "        vbins,zbins,zbins_coarse,vbins_all,zbins_all,zbins_coarse_all,vbins_table = get_bins(question,answer)\n",
    "        print('Bins obtained from previous iteration...')\n",
    "        \n",
    "    else:\n",
    "        vbins,zbins,zbins_coarse,vbins_all,zbins_all,zbins_coarse_all,vbins_table = binning.bin_data(data,full_data,question,answer,plot=False,signal=n_per_bin)\n",
    "    \n",
    "    debiased_bin = bin_debiasing.debias(data,full_data,vbins,zbins,vbins_all,zbins_all,question,answer)\n",
    "    debiased_fit,fit_vbin_results,fit_setup = debias_by_fit(data,full_data,vbins,zbins,zbins_coarse,function_dictionary,min_log_fv)\n",
    "    \n",
    "    volume_ok = data['in_volume_limit'] == 1\n",
    "    vl_data = full_data[volume_ok]\n",
    "    vl_fit = debiased_fit[volume_ok]\n",
    "    vl_bin = debiased_bin[volume_ok]\n",
    "\n",
    "    debiased = choose_best_function(vl_data,vl_fit,vl_bin,debiased_fit,debiased_bin)\n",
    "    full_data[question + '_' + answer + '_debiased_rh'] = debiased\n",
    "    \n",
    "    (os.mkdir('output_files/'+ question) if\n",
    "     os.path.isdir('output_files/'+ question) is False else None)\n",
    "    (os.mkdir('output_files/'+ question + '/' + answer) if\n",
    "     os.path.isdir('output_files/'+ question + '/' + answer) is False else None)\n",
    "\n",
    "    bin_table = Table([vbins,zbins,zbins_coarse],names=('vbin','zbin','coarse_zbin'))\n",
    "    all_bin_table = Table([vbins_all,zbins_all,zbins_coarse_all],names=('vbin','zbin','coarse_zbin'))\n",
    "    debiased_table = Table([debiased_bin,debiased_fit],names=('bin_method','fit_method'))\n",
    "\n",
    "    bin_table.write('output_files/'+ question + '/' + answer + '/bins.fits',overwrite=True)\n",
    "    all_bin_table.write('output_files/'+ question + '/' + answer + '/all_bins.fits',overwrite=True)\n",
    "    debiased_table.write('output_files/'+ question + '/' + answer + '/debiased.fits',overwrite=True)\n",
    "    fit_vbin_results.write('output_files/'+ question + '/' + answer + '/fit_results.fits',overwrite=True)\n",
    "    vbins_table.write('output_files/'+ question + '/' + answer + '/vbin_parameters.fits',overwrite=True)\n",
    "    \n",
    "    pickle.dump(fit_setup,open('output_files/'+ question + '/' + answer + '/fit_setup.p', \"wb\" ))\n",
    "    \n",
    "    return debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Question to be debiased: t11_arms_number\n",
      "Answer to be debiased: a31_1\n",
      "54961/228201 galaxies with p>0.5 and N>=5.\n",
      "Bin-accretion...\n",
      "238  initial bins.\n",
      "Reassign bad bins...\n",
      "21  good bins.\n",
      "Modified Lloyd algorithm...\n",
      "19  iterations.\n",
      "Unbinned pixels:  0  /  4206\n",
      "Fractional S/N scatter (%): 10.4354320717\n",
      "21 voronoi bins\n",
      "30.857142857142858 redshift bins per voronoi bin\n",
      "All bins fitted! 8.815732717514038s in total\n",
      "chisq(logistic) = 0.0017547946934098593\n",
      "All bins fitted! 14.637715816497803s in total\n",
      "chisq(exp. power) = 1.19810033394046e-05\n",
      "All bins fitted! 73.23438382148743s in total\n",
      "RMS residual from fitting method = 0.143\n",
      "RMS residual from binning method = 0.163\n",
      "---> Fitting method selected\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Question to be debiased: t11_arms_number\n",
      "Answer to be debiased: a32_2\n",
      "54961/228201 galaxies with p>0.5 and N>=5.\n",
      "Bin-accretion...\n",
      "384  initial bins.\n",
      "Reassign bad bins...\n",
      "23  good bins.\n",
      "Modified Lloyd algorithm...\n",
      "21  iterations.\n",
      "Unbinned pixels:  0  /  7732\n",
      "Fractional S/N scatter (%): 11.1035135817\n",
      "23 voronoi bins\n",
      "55.69565217391305 redshift bins per voronoi bin\n",
      "All bins fitted! 14.238214015960693s in total\n",
      "chisq(logistic) = 0.00021369357054798314\n",
      "All bins fitted! 17.096837997436523s in total\n",
      "chisq(exp. power) = 8.880281967788836e-05\n",
      "All bins fitted! 145.23263335227966s in total\n",
      "RMS residual from fitting method = 0.525\n",
      "RMS residual from binning method = 0.567\n",
      "---> Fitting method selected\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Question to be debiased: t11_arms_number\n",
      "Answer to be debiased: a33_3\n",
      "54961/228201 galaxies with p>0.5 and N>=5.\n",
      "Bin-accretion...\n",
      "157  initial bins.\n",
      "Reassign bad bins...\n",
      "22  good bins.\n",
      "Modified Lloyd algorithm...\n",
      "20  iterations.\n",
      "Unbinned pixels:  0  /  4248\n",
      "Fractional S/N scatter (%): 13.7882992638\n",
      "22 voronoi bins\n",
      "29.727272727272727 redshift bins per voronoi bin\n",
      "All bins fitted! 9.466392517089844s in total\n",
      "chisq(logistic) = 0.0019475245305020606\n",
      "All bins fitted! 17.368181943893433s in total\n",
      "chisq(exp. power) = 1.6023742128626746e-05\n",
      "All bins fitted! 75.49067115783691s in total\n",
      "RMS residual from fitting method = 0.212\n",
      "RMS residual from binning method = 0.232\n",
      "---> Fitting method selected\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Question to be debiased: t11_arms_number\n",
      "Answer to be debiased: a34_4\n",
      "54961/228201 galaxies with p>0.5 and N>=5.\n",
      "Bin-accretion...\n",
      "157  initial bins.\n",
      "Reassign bad bins...\n",
      "24  good bins.\n",
      "Modified Lloyd algorithm...\n",
      "22  iterations.\n",
      "Unbinned pixels:  0  /  2430\n",
      "Fractional S/N scatter (%): 11.3760561385\n",
      "24 voronoi bins\n",
      "15.25 redshift bins per voronoi bin\n",
      "All bins fitted! 9.295849800109863s in total\n",
      "chisq(logistic) = 0.005729616673519206\n",
      "All bins fitted! 13.482177972793579s in total\n",
      "chisq(exp. power) = 2.06520950580688e-05\n",
      "All bins fitted! 46.507792234420776s in total\n",
      "RMS residual from fitting method = 0.163\n",
      "RMS residual from binning method = 0.153\n",
      "---> Binning method selected\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Question to be debiased: t11_arms_number\n",
      "Answer to be debiased: a36_more_than_4\n",
      "54961/228201 galaxies with p>0.5 and N>=5.\n",
      "Bin-accretion...\n",
      "151  initial bins.\n",
      "Reassign bad bins...\n",
      "23  good bins.\n",
      "Modified Lloyd algorithm...\n",
      "21  iterations.\n",
      "Unbinned pixels:  0  /  1807\n",
      "Fractional S/N scatter (%): 15.1688199887\n",
      "23 voronoi bins\n",
      "11.26086956521739 redshift bins per voronoi bin\n",
      "All bins fitted! 8.915774822235107s in total\n",
      "chisq(logistic) = 0.008072660270078764\n",
      "All bins fitted! 13.068244457244873s in total\n",
      "chisq(exp. power) = 1.3845058678744235e-05\n",
      "All bins fitted! 34.138444662094116s in total\n",
      "RMS residual from fitting method = 0.098\n",
      "RMS residual from binning method = 0.113\n",
      "---> Fitting method selected\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "Question to be debiased: t11_arms_number\n",
      "Answer to be debiased: a37_cant_tell\n",
      "54961/228201 galaxies with p>0.5 and N>=5.\n",
      "Bin-accretion...\n",
      "368  initial bins.\n",
      "Reassign bad bins...\n",
      "23  good bins.\n",
      "Modified Lloyd algorithm...\n",
      "21  iterations.\n",
      "Unbinned pixels:  0  /  7308\n",
      "Fractional S/N scatter (%): 7.7710135186\n",
      "23 voronoi bins\n",
      "51.30434782608695 redshift bins per voronoi bin\n",
      "All bins fitted! 13.073787689208984s in total\n",
      "chisq(logistic) = 0.00048091705699359455\n",
      "All bins fitted! 16.147453784942627s in total\n",
      "chisq(exp. power) = 6.218867734316053e-05\n",
      "All bins fitted! 130.9961006641388s in total\n",
      "RMS residual from fitting method = 0.509\n",
      "RMS residual from binning method = 0.653\n",
      "---> Fitting method selected\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "question_order = [#'t01_smooth_or_features'\n",
    "                  #,'t02_edgeon'\n",
    "                  #,'t04_spiral'\n",
    "                  't11_arms_number']\n",
    "\n",
    "imp.reload(fit_debiasing)\n",
    "\n",
    "for question in question_order:\n",
    "    \n",
    "    for answer in questions[question]['answers']:\n",
    "        \n",
    "        #bins_exist = os.path.isfile('output_files/'+ question + '/' + answer + '/bins.fits')\n",
    "        bins_exist = False\n",
    "        \n",
    "        print('----------------------------------')\n",
    "        print('Question to be debiased:',question)\n",
    "        print('Answer to be debiased:',answer)\n",
    "        debiased = bin_and_debias(full_data,question,questions,answer,bins_exist=bins_exist,n_per_bin=40)\n",
    "        print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data.write(source_directory + 'full_sample_debiased.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "debiased_columns = ['t01_smooth_or_features_a01_smooth_debiased_rh',\n",
    "                    't01_smooth_or_features_a02_features_or_disk_debiased_rh',\n",
    "                    't01_smooth_or_features_a03_star_or_artifact_debiased_rh',\n",
    "                    't02_edgeon_a04_yes_debiased_rh',\n",
    "                    't02_edgeon_a05_no_debiased_rh',\n",
    "                    't04_spiral_a08_spiral_debiased_rh',\n",
    "                    't04_spiral_a09_no_spiral_debiased_rh',\n",
    "                    't11_arms_number_a31_1_debiased_rh',\n",
    "                    't11_arms_number_a32_2_debiased_rh',\n",
    "                    't11_arms_number_a33_3_debiased_rh',\n",
    "                    't11_arms_number_a34_4_debiased_rh',\n",
    "                    't11_arms_number_a36_more_than_4_debiased_rh',\n",
    "                    't11_arms_number_a37_cant_tell_debiased_rh']\n",
    "\n",
    "debiased_values = full_data[debiased_columns]\n",
    "debiased_values.write(source_directory + 'debiased_values.fits',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp.reload(fit_debiasing)\n",
    "imp.reload(make_dictionaries)\n",
    "questions = make_dictionaries.questions\n",
    "print('Loaded questions...')\n",
    "function_dictionary = make_dictionaries.function_dictionary\n",
    "print('Loaded functions...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_fit_setup(function_dictionary,key):\n",
    "    fit_setup = {}\n",
    "    fit_setup['func'] = function_dictionary['func'][key]\n",
    "    fit_setup['bounds'] = function_dictionary['bounds'][key]\n",
    "    fit_setup['p0'] = function_dictionary['p0'][key]\n",
    "    fit_setup['inverse'] = function_dictionary['i_func'][key]\n",
    "    return fit_setup\n",
    "\n",
    "\n",
    "def chisq_fun(p, f, x, y):\n",
    "    return ((f(x, *p) - y)**2).sum()\n",
    "\n",
    "\n",
    "data = reduce_sample(full_data,questions,question)\n",
    "\n",
    "fv_all = np.sort(data[question + '_' + answer + '_weighted_fraction'])\n",
    "fv_nonzero = fv_all != 0\n",
    "cf = np.linspace(0,1,len(fv_all))\n",
    "x,y = [np.log10(fv_all[fv_nonzero]),cf[fv_nonzero]]\n",
    "    \n",
    "x_fit = np.log10(np.linspace(10**(min_log_fv), 1, 100))\n",
    "indices = np.searchsorted(x,x_fit)\n",
    "y_fit = y[indices]\n",
    "    \n",
    "chisq_tot = np.zeros(len(function_dictionary['func'].keys()))\n",
    "k_tot = np.zeros(len(function_dictionary['func'].keys()))\n",
    "c_tot = np.zeros(len(function_dictionary['func'].keys()))\n",
    "    \n",
    "for n,key in enumerate(function_dictionary['func'].keys()):\n",
    "        # Overall data fitting:\n",
    "    fit_setup = make_fit_setup(function_dictionary,key)\n",
    "    \n",
    "    #print(fit_setup)\n",
    "    #func = fit_setup['func']\n",
    "    #p0 = fit_setup['p0']\n",
    "    #bounds = fit_setup['bounds']\n",
    "    \n",
    "    #print(p0)\n",
    "        \n",
    "    #res =  minimize(chisq_fun, p0,\n",
    "                    #args=(func,x_fit,y_fit),\n",
    "                    #bounds=bounds,method='SLSQP')\n",
    "        \n",
    "    #function_dictionary['p0'][key] = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "func = function_dictionary['func'][1]\n",
    "bounds = function_dictionary['bounds'][1]\n",
    "p0 = function_dictionary['p0'][1]\n",
    "\n",
    "data = reduce_sample(full_data,questions,question)\n",
    "bins = Table.read('output_files/'+ question + '/' + answer + '/bins.fits')\n",
    "vbins = bins['vbin']\n",
    "zbins = bins['coarse_zbin']\n",
    "\n",
    "even_sampling = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = 10\n",
    "z = 3\n",
    "\n",
    "fv = question + '_' + answer + '_weighted_fraction'\n",
    "\n",
    "vselect = vbins == v\n",
    "data_v = data[vselect]\n",
    "zbins_v = zbins[vselect]\n",
    "\n",
    "z_bins_unique = np.unique(zbins_v)\n",
    "\n",
    "data_z = data_v[zbins_v == z]\n",
    "n = len(data_z)\n",
    "\n",
    "min_fv = 10**(-1.5)\n",
    "            \n",
    "D = data_z[[fv]]\n",
    "D.sort(fv)\n",
    "D['cumfrac'] = np.linspace(0, 1, n)\n",
    "D = D[D[fv] > min_fv]\n",
    "D['log10fv'] = np.log10(D[fv])\n",
    "\n",
    "#print(len(D[(D['log10fv'] > min_log_fv)]))\n",
    "#plt.plot(D['log10fv'],D['cumfrac'],'b--',linewidth=2)\n",
    "\n",
    "if even_sampling:\n",
    "    D_fit_log10fv = np.log10(np.linspace(10**(min_log_fv), 1, 100))\n",
    "    D = D[(D['log10fv'] > min_log_fv)] #& (D['log10fv'] < max_log_fv)]\n",
    "    indices = np.searchsorted(D['log10fv'], D_fit_log10fv)\n",
    "    D_fit = D[indices.clip(0, len(D)-1)]\n",
    "else:\n",
    "    D_fit = D[D['log10fv'] > min_log_fv]\n",
    "\n",
    "res = minimize(chisq_fun, p0,\n",
    "                args=(func,\n",
    "                      D_fit['log10fv'].astype(np.float64),\n",
    "                      D_fit['cumfrac'].astype(np.float64)),\n",
    "                      bounds=bounds, method='SLSQP')\n",
    "            \n",
    "p = res.x\n",
    "\n",
    "xg = np.linspace(-1.2,0,1000)\n",
    "\n",
    "plt.plot(D_fit['log10fv'],D_fit['cumfrac'],'k-',linewidth=2)\n",
    "plt.plot(xg,func(xg,*p),'r--')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
